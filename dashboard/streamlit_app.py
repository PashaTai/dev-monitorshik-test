"""
Streamlit dashboard for monitoring comment sentiment.

This module provides data-loading helpers and aggregation utilities that the
Streamlit UI layer can reuse.  The UI components will be defined below these
helpers so that tests (or CLI experiments) can import the functions without
initialising Streamlit.
"""
from __future__ import annotations

import os
import requests
from dataclasses import dataclass
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, Tuple

import pandas as pd
import streamlit as st
import altair as alt
from sqlalchemy import create_engine, func, select
from sqlalchemy.engine import Engine
from sqlalchemy.orm import Session

from config.settings import Settings
from database.models import Comment


# -----------------------------------------------------------------------------
# Authentication
# -----------------------------------------------------------------------------


def check_password() -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–æ–ª—è –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ dashboard
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω
    """
    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–æ–ª—å –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
    correct_password = os.getenv("DASHBOARD_PASSWORD", "admin123")
    
    # –ï—Å–ª–∏ —É–∂–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω
    if st.session_state.get("authenticated", False):
        return True
    
    # –§–æ—Ä–º–∞ –≤—Ö–æ–¥–∞
    st.title("üîê –í—Ö–æ–¥ –≤ —Å–∏—Å—Ç–µ–º—É")
    st.markdown("–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ dashboard")
    
    with st.form("login_form"):
        password = st.text_input("–ü–∞—Ä–æ–ª—å", type="password")
        submit = st.form_submit_button("–í–æ–π—Ç–∏")
        
        if submit:
            if password == correct_password:
                st.session_state["authenticated"] = True
                st.success("‚úÖ –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞!")
                st.rerun()
            else:
                st.error("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å")
    
    return False


# -----------------------------------------------------------------------------
# Data access helpers
# -----------------------------------------------------------------------------


def _resolve_db_path(db_path: Optional[str] = None) -> Path:
    """
    Resolve the SQLite database path.

    If the caller does not provide a path we fall back to the application
    settings (env var `DB_PATH`, default `comments.db`).
    """
    if db_path:
        return Path(db_path).expanduser().resolve()

    Settings.load()
    return Path(Settings.DB_PATH).expanduser().resolve()


def create_sqlite_engine(db_path: Optional[str] = None) -> Engine:
    """Create a SQLAlchemy engine for the SQLite comments database."""
    resolved = _resolve_db_path(db_path)
    return create_engine(
        f"sqlite:///{resolved}",
        connect_args={"check_same_thread": False},
    )


def get_session(engine: Engine) -> Session:
    """Get a SQLAlchemy session bound to the provided engine."""
    from sqlalchemy.orm import sessionmaker

    SessionLocal = sessionmaker(bind=engine)
    return SessionLocal()


# -----------------------------------------------------------------------------
# Data loading & aggregation layer
# -----------------------------------------------------------------------------


def fetch_comments_dataframe(
    engine: Engine,
    date_range: Optional[Tuple[datetime, datetime]] = None,
    source: Optional[str] = None,
) -> pd.DataFrame:
    """
    Load comments into a pandas DataFrame applying optional filters.

    Parameters
    ----------
    engine:
        SQLAlchemy engine pointing to the comments database.
    date_range:
        Optional tuple (start_datetime, end_datetime).  Boundaries are inclusive.
    source:
        Optional platform filter. Accepts `'vk'`, `'telegram'`, or `None` for all.
    """
    with engine.connect() as conn:
        stmt = select(Comment)
        if source and source != "all":
            stmt = stmt.filter(Comment.source == source)

        if date_range:
            start, end = date_range
            if start:
                stmt = stmt.filter(Comment.comment_published_at >= start)
            if end:
                stmt = stmt.filter(Comment.comment_published_at <= end)

        df = pd.read_sql(stmt, conn)

    if not df.empty:
        datetime_columns = [
            "post_published_at",
            "comment_published_at",
            "parsed_at",
        ]
        for column in datetime_columns:
            if column in df.columns:
                df[column] = pd.to_datetime(df[column])

    return df


def sentiment_breakdown(df: pd.DataFrame) -> pd.Series:
    """
    Return sentiment distribution including 'undefined' bucket.

    The database stores `None` for unprocessed comments; they are reported as
    `'undefined'` so the frontend can display them explicitly.
    """
    if df.empty:
        return pd.Series(dtype=int)

    sentiments = df["sentiment"].fillna("undefined")
    return sentiments.value_counts().reindex(
        ["positive", "negative", "neutral", "undefined"], fill_value=0
    )


def daily_sentiment_percentages(df: pd.DataFrame) -> pd.DataFrame:
    """
    Aggregate sentiment percentages by day.

    The resulting frame has columns:
        - `date` (datetime) ‚Äì the date
        - `positive_pct` (percentage of positive)
        - `negative_pct` (percentage of negative)
        - `neutral_pct` (percentage of neutral)
    """
    if df.empty:
        return pd.DataFrame(columns=["date", "positive_pct", "negative_pct", "neutral_pct"])

    # Filter only comments with sentiment defined
    filtered = df[df["sentiment"].isin(["positive", "negative", "neutral"])].copy()
    if filtered.empty:
        return pd.DataFrame(columns=["date", "positive_pct", "negative_pct", "neutral_pct"])

    # Extract date only (without time)
    filtered["date"] = filtered["comment_published_at"].dt.date

    # Count sentiments per day
    grouped = filtered.groupby("date")["sentiment"].value_counts().unstack(fill_value=0)
    grouped = grouped.reindex(columns=["positive", "negative", "neutral"], fill_value=0)
    
    # Calculate total per day and percentages (keep raw counts for tooltip)
    grouped["total"] = grouped.sum(axis=1)
    grouped["positive_pct"] = (grouped["positive"] / grouped["total"] * 100)
    grouped["negative_pct"] = (grouped["negative"] / grouped["total"] * 100)
    grouped["neutral_pct"] = (grouped["neutral"] / grouped["total"] * 100)
    
    # Keep counts for tooltip
    grouped["positive_count"] = grouped["positive"]
    grouped["negative_count"] = grouped["negative"]
    grouped["neutral_count"] = grouped["neutral"]
    
    # Reset index and convert date back to datetime for plotting
    grouped = grouped.reset_index()
    grouped["date"] = pd.to_datetime(grouped["date"])
    
    return grouped[["date", "positive_pct", "negative_pct", "neutral_pct", 
                    "positive_count", "negative_count", "neutral_count"]].sort_values("date")


def get_comment_date_bounds(engine: Engine) -> Tuple[Optional[datetime], Optional[datetime]]:
    """Return min/max `comment_published_at` timestamps."""
    with engine.connect() as conn:
        result = conn.execute(
            select(
                func.min(Comment.comment_published_at),
                func.max(Comment.comment_published_at),
            )
        ).first()

    if not result:
        return None, None

    return result[0], result[1]


def get_available_sources(engine: Engine) -> list[str]:
    """Fetch distinct sources from the comments table."""
    with engine.connect() as conn:
        rows = conn.execute(select(Comment.source).distinct()).fetchall()
    return sorted({row[0] for row in rows if row[0]})


@dataclass
class PostSummary:
    post_url: str
    group_channel_name: str
    comment_count: int
    negative_count: int


def post_highlights(df: pd.DataFrame) -> Tuple[Optional[PostSummary], Optional[PostSummary]]:
    """
    Determine posts with most comments and most negative comments.

    Returns
    -------
    tuple(PostSummary | None, PostSummary | None)
        First item is the post with the highest total comment count.
        Second item is the post with the highest negative comment count.
    """
    if df.empty:
        return None, None

    grouped = (
        df.groupby(["post_url", "group_channel_name"])
        .agg(
            comment_count=("id", "count"),
            negative_count=(
                "sentiment",
                lambda s: (s == "negative").sum(),
            ),
        )
        .reset_index()
    )

    if grouped.empty:
        return None, None

    top_comment_row = grouped.sort_values("comment_count", ascending=False).iloc[0]
    top_negative_row = grouped.sort_values("negative_count", ascending=False).iloc[0]

    top_comment = PostSummary(
        post_url=top_comment_row["post_url"],
        group_channel_name=top_comment_row["group_channel_name"],
        comment_count=int(top_comment_row["comment_count"]),
        negative_count=int(top_comment_row["negative_count"]),
    )

    top_negative = PostSummary(
        post_url=top_negative_row["post_url"],
        group_channel_name=top_negative_row["group_channel_name"],
        comment_count=int(top_negative_row["comment_count"]),
        negative_count=int(top_negative_row["negative_count"]),
    )

    return top_comment, top_negative


def prepare_raw_table(df: pd.DataFrame) -> pd.DataFrame:
    """
    Return a cleaned dataframe for the raw data table.

    Applies basic sorting and ensures datetime columns are formatted.
    """
    if df.empty:
        return df

    columns_order = [
        "id",
        "source",
        "group_channel_name",
        "post_url",
        "comment_url",
        "author_name",
        "comment_text",
        "sentiment",
        "sentiment_score",
        "comment_published_at",
        "parsed_at",
    ]

    available_columns = [col for col in columns_order if col in df.columns]
    remainder = [col for col in df.columns if col not in available_columns]

    table = df[available_columns + remainder].copy()
    table = table.sort_values("comment_published_at", ascending=False)
    return table.reset_index(drop=True)


def render_header(db_path: Path) -> None:
    st.set_page_config(
        page_title="Unified Monitor Dashboard",
        layout="wide",
        page_icon="üìä",
    )
    st.title("Unified Monitor ‚Äî –¥–∞—à–±–æ—Ä–¥ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤")
    st.caption(
        f"–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö: `{db_path}`. "
        "–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—É—Ç—å –∏ —Ñ–∏–ª—å—Ç—Ä—ã –≤ –ª–µ–≤–æ–º —Å–∞–π–¥–±–∞—Ä–µ."
    )


def sidebar_controls(default_db_path: Path) -> tuple[Path, tuple[datetime, datetime], str]:
    st.sidebar.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

    db_path_str = st.sidebar.text_input(
        "–ü—É—Ç—å –∫ –±–∞–∑–µ SQLite",
        value=str(default_db_path),
    )
    db_path = Path(db_path_str).expanduser()

    try:
        engine = create_sqlite_engine(str(db_path))
        min_date, max_date = get_comment_date_bounds(engine)
    except Exception as exc:  # pragma: no cover - Streamlit feedback
        st.sidebar.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ: {exc}")
        raise

    if not db_path.exists():
        st.sidebar.warning("–§–∞–π–ª –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å.")

    if not min_date or not max_date:
        default_start = datetime.utcnow() - timedelta(days=7)
        default_end = datetime.utcnow()
    else:
        default_start = min_date
        default_end = max_date

    period = st.sidebar.date_input(
        "–ü–µ—Ä–∏–æ–¥ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤",
        value=(default_start.date(), default_end.date()),
        min_value=(min_date.date() if min_date else None),
        max_value=(max_date.date() if max_date else None),
    )

    if isinstance(period, tuple):
        if len(period) == 2:
            start_date, end_date = period
        elif len(period) == 1:
            start_date = end_date = period[0]
        else:
            # Fallback
            start_date = end_date = default_start.date()
    else:
        # Single date selected
        start_date = end_date = period

    # Convert to datetime boundaries inclusive
    start_dt = datetime.combine(start_date, datetime.min.time())
    end_dt = datetime.combine(end_date, datetime.max.time())

    sources = get_available_sources(engine)
    source_option = st.sidebar.selectbox(
        "–ü–ª–æ—â–∞–¥–∫–∞",
        options=["all"] + sources,
        format_func=lambda value: {
            "all": "–í—Å–µ –ø–ª–æ—â–∞–¥–∫–∏",
            "vk": "–í–ö–æ–Ω—Ç–∞–∫—Ç–µ",
            "telegram": "Telegram",
        }.get(value, value),
    )

    return db_path, (start_dt, end_dt), source_option


def kpi_section(df: pd.DataFrame) -> None:
    total_comments = int(len(df))
    sentiments = sentiment_breakdown(df)

    positive = int(sentiments.get("positive", 0))
    negative = int(sentiments.get("negative", 0))
    neutral = int(sentiments.get("neutral", 0))
    undefined = int(sentiments.get("undefined", 0))

    st.subheader("–°–≤–æ–¥–∫–∞ –ø–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—è–º")
    col_total, col_pos, col_neg, col_neu, col_undef = st.columns(5)
    col_total.metric("–í—Å–µ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤", f"{total_comments:,}".replace(",", " "))
    col_pos.metric("–ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö", positive, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —Å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é 'positive'")
    col_neg.metric("–ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö", negative, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —Å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é 'negative'")
    col_neu.metric("–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö", neutral, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —Å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é 'neutral'")
    col_undef.metric("–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ", undefined, help="–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –±–µ–∑ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")


def daily_histogram_section(df: pd.DataFrame) -> None:
    st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –¥–Ω—è–º (–≤ %)")
    daily_df = daily_sentiment_percentages(df)

    if daily_df.empty:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã.")
        return

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ long-—Ñ–æ—Ä–º–∞—Ç –¥–ª—è stacked bar chart, –¥–æ–±–∞–≤–ª—è–µ–º counts
    chart_data = daily_df.melt(
        id_vars=["date", "positive_count", "negative_count", "neutral_count"],
        value_vars=["positive_pct", "negative_pct", "neutral_pct"],
        var_name="sentiment",
        value_name="percentage",
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ counts –¥–ª—è –∫–∞–∂–¥–æ–≥–æ sentiment
    def get_count(row):
        if row["sentiment"] == "positive_pct":
            return row["positive_count"]
        elif row["sentiment"] == "negative_pct":
            return row["negative_count"]
        else:
            return row["neutral_count"]
    
    chart_data["count"] = chart_data.apply(get_count, axis=1)
    
    # –ü–µ—Ä–µ–∏–º–µ–Ω—É–µ–º –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    sentiment_map = {
        "positive_pct": "–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ",
        "negative_pct": "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ",
        "neutral_pct": "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ"
    }
    chart_data["sentiment"] = chart_data["sentiment"].map(sentiment_map)

    chart = (
        alt.Chart(chart_data)
        .mark_bar()
        .encode(
            x=alt.X(
                "date:T", 
                title="–î–∞—Ç–∞",
                axis=alt.Axis(
                    format="%d.%m.%Y",
                    formatType="time",
                    labelAngle=-45,
                    tickCount="day"
                )
            ),
            y=alt.Y("percentage:Q", title="–ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∑–∞ –¥–µ–Ω—å (%)", stack="zero"),
            color=alt.Color(
                "sentiment:N",
                title="–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å",
                scale=alt.Scale(
                    domain=["–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ", "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ", "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ"],
                    range=["#4CAF50", "#9E9E9E", "#F44336"],
                ),
            ),
            tooltip=[
                alt.Tooltip("date:T", title="–î–∞—Ç–∞", format="%d.%m.%Y"),
                alt.Tooltip("sentiment:N", title="–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å"),
                alt.Tooltip("count:Q", title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"),
                alt.Tooltip("percentage:Q", title="–ü—Ä–æ—Ü–µ–Ω—Ç", format=".1f"),
            ],
        )
        .properties(height=360)
    )

    st.altair_chart(chart, use_container_width=True)


def post_summary_section(df: pd.DataFrame) -> None:
    st.subheader("–õ–∏–¥–µ—Ä—ã –ø–æ –ø–æ—Å—Ç–∞–º")
    top_comment, top_negative = post_highlights(df)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**–ë–æ–ª—å—à–µ –≤—Å–µ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤**")
        if top_comment:
            st.metric(
                label=top_comment.group_channel_name,
                value=f"{top_comment.comment_count} –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤",
                delta=f"{top_comment.negative_count} –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö",
                delta_color="inverse",
            )
            st.markdown(f"[–ü–µ—Ä–µ–π—Ç–∏ –∫ –ø–æ—Å—Ç—É]({top_comment.post_url})")
        else:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø–æ—Å—Ç–∞–º.")

    with col2:
        st.markdown("**–ë–æ–ª—å—à–µ –≤—Å–µ–≥–æ –Ω–µ–≥–∞—Ç–∏–≤–∞**")
        if top_negative:
            st.metric(
                label=top_negative.group_channel_name,
                value=f"{top_negative.negative_count} –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö",
                delta=f"{top_negative.comment_count} –≤—Å–µ–≥–æ",
            )
            st.markdown(f"[–ü–µ—Ä–µ–π—Ç–∏ –∫ –ø–æ—Å—Ç—É]({top_negative.post_url})")
        else:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º.")


def raw_data_section(df: pd.DataFrame) -> None:
    st.subheader("Raw Data")
    raw_table = prepare_raw_table(df)

    if raw_table.empty:
        st.info("–ù–µ—Ç —Å—Ç—Ä–æ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ç–∞–±–ª–∏—Ü–µ.")
        return

    st.dataframe(raw_table, use_container_width=True, hide_index=True)

    csv_data = raw_table.to_csv(index=False).encode("utf-8")
    st.download_button(
        "–°–∫–∞—á–∞—Ç—å CSV",
        data=csv_data,
        file_name="comments_export.csv",
        mime="text/csv",
    )


def manual_labeling_section(selected_range: Tuple[datetime, datetime]) -> None:
    """
    –°–µ–∫—Ü–∏—è –¥–ª—è —Ä—É—á–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    
    Args:
        selected_range: –í—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ (start_datetime, end_datetime)
    """
    st.subheader("üè∑Ô∏è –†—É—á–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ API –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    api_url = os.getenv("API_URL", "http://localhost:8000")
    api_username = os.getenv("API_USERNAME", "admin")
    api_password = os.getenv("API_PASSWORD", "changeme")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API
    try:
        response = requests.get(f"{api_url}/api/health", timeout=2)
        if response.status_code != 200:
            st.error(f"‚ö†Ô∏è API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ {api_url}")
            return
    except requests.exceptions.RequestException:
        st.error(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ API –Ω–∞ {api_url}")
        st.info("–£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ api_server.py –∑–∞–ø—É—â–µ–Ω")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
    start_dt, end_dt = selected_range
    
    try:
        response = requests.get(
            f"{api_url}/api/comments/undefined",
            params={
                "start_date": start_dt.strftime("%Y-%m-%d"),
                "end_date": end_dt.strftime("%Y-%m-%d"),
                "limit": 50  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ 50 –∑–∞ —Ä–∞–∑
            },
            auth=(api_username, api_password),
            timeout=10
        )
        
        if response.status_code == 401:
            st.error("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–µ —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è API")
            return
        
        response.raise_for_status()
        undefined_comments = response.json()
        
    except requests.exceptions.RequestException as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {e}")
        return
    
    if not undefined_comments:
        st.success("‚úÖ –í—Å–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –ø–µ—Ä–∏–æ–¥–µ —Ä–∞–∑–º–µ—á–µ–Ω—ã!")
        return
    
    st.info(f"–ù–∞–π–¥–µ–Ω–æ {len(undefined_comments)} –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è
    if "current_comment_index" not in st.session_state:
        st.session_state["current_comment_index"] = 0
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –∏–Ω–¥–µ–∫—Å –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –º–∞—Å—Å–∏–≤–∞
    if st.session_state["current_comment_index"] >= len(undefined_comments):
        st.session_state["current_comment_index"] = 0
    
    if not undefined_comments:
        return
    
    current_idx = st.session_state["current_comment_index"]
    comment = undefined_comments[current_idx]
    
    # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
    progress = (current_idx + 1) / len(undefined_comments)
    st.progress(progress, text=f"–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π {current_idx + 1} –∏–∑ {len(undefined_comments)}")
    
    # –ö–∞—Ä—Ç–æ—á–∫–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è
    with st.container():
        st.markdown("---")
        
        col_info1, col_info2 = st.columns(2)
        with col_info1:
            st.markdown(f"**ID:** {comment['id']}")
            st.markdown(f"**–ò—Å—Ç–æ—á–Ω–∏–∫:** {comment['source']}")
            st.markdown(f"**–ê–≤—Ç–æ—Ä:** {comment['author_name']}")
        
        with col_info2:
            st.markdown(f"**–ö–∞–Ω–∞–ª/–ì—Ä—É–ø–ø–∞:** {comment['group_channel_name']}")
            comment_date = datetime.fromisoformat(comment['comment_published_at'].replace('Z', '+00:00'))
            st.markdown(f"**–î–∞—Ç–∞:** {comment_date.strftime('%d.%m.%Y %H:%M')}")
        
        st.markdown("**–¢–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è:**")
        st.info(comment['comment_text'])
        
        # –°—Å—ã–ª–∫–∏
        col_link1, col_link2 = st.columns(2)
        with col_link1:
            st.markdown(f"[üîó –°—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ—Å—Ç]({comment['post_url']})")
        with col_link2:
            st.markdown(f"[üí¨ –°—Å—ã–ª–∫–∞ –Ω–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π]({comment['comment_url']})")
        
        st.markdown("---")
        
        # –ö–Ω–æ–ø–∫–∏ –≤—ã–±–æ—Ä–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        st.markdown("**–í—ã–±–µ—Ä–∏—Ç–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:**")
        col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
        
        with col1:
            if st.button("üü¢ –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π", key=f"pos_{comment['id']}", use_container_width=True):
                if update_sentiment_via_api(
                    api_url, comment['id'], "positive", 
                    api_username, api_password
                ):
                    st.success("‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ: –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π")
                    st.session_state["current_comment_index"] = min(
                        current_idx + 1, len(undefined_comments) - 1
                    )
                    st.rerun()
        
        with col2:
            if st.button("‚ö™ –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π", key=f"neu_{comment['id']}", use_container_width=True):
                if update_sentiment_via_api(
                    api_url, comment['id'], "neutral",
                    api_username, api_password
                ):
                    st.success("‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ: –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π")
                    st.session_state["current_comment_index"] = min(
                        current_idx + 1, len(undefined_comments) - 1
                    )
                    st.rerun()
        
        with col3:
            if st.button("üî¥ –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π", key=f"neg_{comment['id']}", use_container_width=True):
                if update_sentiment_via_api(
                    api_url, comment['id'], "negative",
                    api_username, api_password
                ):
                    st.success("‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ: –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π")
                    st.session_state["current_comment_index"] = min(
                        current_idx + 1, len(undefined_comments) - 1
                    )
                    st.rerun()
        
        with col4:
            if st.button("‚è≠Ô∏è –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å", key=f"skip_{comment['id']}", use_container_width=True):
                st.session_state["current_comment_index"] = (current_idx + 1) % len(undefined_comments)
                st.rerun()
        
        # –ù–∞–≤–∏–≥–∞—Ü–∏—è
        st.markdown("---")
        nav_col1, nav_col2, nav_col3 = st.columns([1, 2, 1])
        
        with nav_col1:
            if st.button("‚¨ÖÔ∏è –ü—Ä–µ–¥—ã–¥—É—â–∏–π", disabled=(current_idx == 0)):
                st.session_state["current_comment_index"] = current_idx - 1
                st.rerun()
        
        with nav_col3:
            if st.button("–°–ª–µ–¥—É—é—â–∏–π ‚û°Ô∏è", disabled=(current_idx >= len(undefined_comments) - 1)):
                st.session_state["current_comment_index"] = current_idx + 1
                st.rerun()


def update_sentiment_via_api(
    api_url: str, 
    comment_id: int, 
    sentiment: str,
    username: str,
    password: str
) -> bool:
    """
    –û–±–Ω–æ–≤–∏—Ç—å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ API
    
    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
    """
    try:
        response = requests.put(
            f"{api_url}/api/comments/{comment_id}/sentiment",
            json={
                "sentiment": sentiment,
                "sentiment_score": 0.95  # –†—É—á–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –∏–º–µ–µ—Ç –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            },
            auth=(username, password),
            timeout=10
        )
        
        response.raise_for_status()
        return True
        
    except requests.exceptions.RequestException as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏: {e}")
        return False


def main() -> None:
    """
    –ó–∞–ø—É—Å–∫ Streamlit –¥–∞—à–±–æ—Ä–¥–∞.

    –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞:
        streamlit run dashboard/streamlit_app.py
    """
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
    if not check_password():
        st.stop()
    
    default_db_path = _resolve_db_path()
    db_path, selected_range, selected_source = sidebar_controls(default_db_path)
    engine = create_sqlite_engine(str(db_path))

    render_header(db_path)

    df = fetch_comments_dataframe(engine, selected_range, None if selected_source == "all" else selected_source)

    if df.empty:
        st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤.")
        return

    with st.expander("–¢–µ–∫—É—â–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã", expanded=False):
        start_dt, end_dt = selected_range
        st.write(
            f"–ü–µ—Ä–∏–æ–¥: {start_dt.strftime('%d.%m.%Y')} ‚Äî {end_dt.strftime('%d.%m.%Y')}"
        )
        st.write(
            "–ü–ª–æ—â–∞–¥–∫–∞: "
            + ("–í—Å–µ" if selected_source == "all" else selected_source.capitalize())
        )

    kpi_section(df)
    daily_histogram_section(df)
    post_summary_section(df)
    
    # –°–µ–∫—Ü–∏—è —Ä—É—á–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏
    st.markdown("---")
    manual_labeling_section(selected_range)
    
    # Raw data –≤ –∫–æ–Ω—Ü–µ
    st.markdown("---")
    raw_data_section(df)


if __name__ == "__main__":
    main()

